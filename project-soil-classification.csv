{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6b0295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T05:31:34.461918Z",
     "iopub.status.busy": "2025-05-25T05:31:34.461482Z",
     "iopub.status.idle": "2025-05-25T05:31:54.852390Z",
     "shell.execute_reply": "2025-05-25T05:31:54.851570Z"
    },
    "papermill": {
     "duration": 20.398105,
     "end_time": "2025-05-25T05:31:54.854108",
     "exception": false,
     "start_time": "2025-05-25T05:31:34.456003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 05:31:38.395649: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748151098.629754      13 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748151098.698569      13 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "#importing required libraries for this project:-\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3b9371",
   "metadata": {
    "papermill": {
     "duration": 0.003243,
     "end_time": "2025-05-25T05:31:54.861275",
     "exception": false,
     "start_time": "2025-05-25T05:31:54.858032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Tools & Libraries Used**\n",
    "1. Python (main programming language)\n",
    "\n",
    "2. TensorFlow/Keras (for building the neural network)\n",
    "\n",
    "3. NumPy & Pandas (for data handling)\n",
    "\n",
    "4. scikit-learn (for splitting data and evaluation)\n",
    "\n",
    "5. OpenCV (for image processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474a6a51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T05:31:54.870202Z",
     "iopub.status.busy": "2025-05-25T05:31:54.869228Z",
     "iopub.status.idle": "2025-05-25T05:31:54.874417Z",
     "shell.execute_reply": "2025-05-25T05:31:54.873637Z"
    },
    "papermill": {
     "duration": 0.011329,
     "end_time": "2025-05-25T05:31:54.876110",
     "exception": false,
     "start_time": "2025-05-25T05:31:54.864781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "\n",
    "# Data paths (adjust to your actual paths)\n",
    "TRAIN_DIR = '/kaggle/input/soil-classification/soil_classification-2025/train'\n",
    "TEST_DIR = '/kaggle/input/soil-classification/soil_classification-2025/test'\n",
    "TRAIN_CSV = '/kaggle/input/soil-classification/soil_classification-2025/train_labels.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d184c95e",
   "metadata": {
    "papermill": {
     "duration": 0.003164,
     "end_time": "2025-05-25T05:31:54.882943",
     "exception": false,
     "start_time": "2025-05-25T05:31:54.879779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Configuration Settings\n",
    "\n",
    "Image Settings:\n",
    "  - `IMG_SIZE = (224, 224)` → All soil images will be resized to 224x224 pixels\n",
    "  - `BATCH_SIZE = 32` → Processes 32 images at once during training\n",
    "\n",
    "Training Control:\n",
    "  - `EPOCHS = 30` → The model will go through the entire dataset 30 times\n",
    "\n",
    "File Paths:\n",
    "  - `TRAIN_DIR` → Location of training images\n",
    "  - `TEST_DIR` → Location of test images\n",
    "  - `TRAIN_CSV` → File containing image labels (what soil type each image shows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b544b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T05:31:54.891020Z",
     "iopub.status.busy": "2025-05-25T05:31:54.890667Z",
     "iopub.status.idle": "2025-05-25T05:31:54.940338Z",
     "shell.execute_reply": "2025-05-25T05:31:54.939043Z"
    },
    "papermill": {
     "duration": 0.055682,
     "end_time": "2025-05-25T05:31:54.941971",
     "exception": false,
     "start_time": "2025-05-25T05:31:54.886289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data class distribution:\n",
      "soil_type\n",
      "Alluvial soil    43.2%\n",
      "Red soil         21.6%\n",
      "Black Soil       18.9%\n",
      "Clay soil        16.3%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare data\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "test_files = [f for f in os.listdir(TEST_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "test_df = pd.DataFrame({'image_id': test_files})\n",
    "\n",
    "# Verifying classes \n",
    "print(\"Training data class distribution:\")\n",
    "print(train_df['soil_type'].value_counts(normalize=True).apply(lambda x: f\"{x:.1%}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e173147b",
   "metadata": {
    "papermill": {
     "duration": 0.003212,
     "end_time": "2025-05-25T05:31:54.948964",
     "exception": false,
     "start_time": "2025-05-25T05:31:54.945752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**loads soil image data from files & checks distribution of different soil types in training set:**\n",
    "\n",
    "\n",
    "1. Reads the training labels from CSV\n",
    "2. Finds all test images in the test folder\n",
    "3. Shows what percentage of each soil type we have in our training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237d053e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T05:31:54.957179Z",
     "iopub.status.busy": "2025-05-25T05:31:54.956870Z",
     "iopub.status.idle": "2025-05-25T05:31:58.836384Z",
     "shell.execute_reply": "2025-05-25T05:31:58.835469Z"
    },
    "papermill": {
     "duration": 3.885477,
     "end_time": "2025-05-25T05:31:58.837974",
     "exception": false,
     "start_time": "2025-05-25T05:31:54.952497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 972 validated image filenames belonging to 4 classes.\n",
      "Found 242 validated image filenames belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 8 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 8 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 339 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=TRAIN_DIR,\n",
    "    x_col='image_id',\n",
    "    y_col='soil_type',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=TRAIN_DIR,\n",
    "    x_col='image_id',\n",
    "    y_col='soil_type',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    directory=TEST_DIR,\n",
    "    x_col='image_id',\n",
    "    y_col=None,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d441e7",
   "metadata": {
    "papermill": {
     "duration": 0.003489,
     "end_time": "2025-05-25T05:31:58.845516",
     "exception": false,
     "start_time": "2025-05-25T05:31:58.842027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Data Preparation\n",
    "\n",
    "- **Image Processing**:\n",
    "  - Normalizes pixel values (0-1) by dividing by 255\n",
    "  - Adds variations to training images:\n",
    "    - Random rotations (up to 20 degrees)\n",
    "    - Small left/right and up/down shifts\n",
    "    - Horizontal flipping\n",
    "  - Keeps test images unchanged (only normalizes them)\n",
    "\n",
    "- **Data Generators**:\n",
    "  - `train_generator`: \n",
    "    - Takes images from training folder\n",
    "    - Uses 80% of data for actual training\n",
    "    - Shuffles images for better learning\n",
    "  - `val_generator`: \n",
    "    - Uses remaining 20% for validation\n",
    "    - Doesn't shuffle (for proper evaluation)\n",
    "  - `test_generator`:\n",
    "    - Only for final testing\n",
    "    - No labels needed (for predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f580ffb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T05:31:58.854152Z",
     "iopub.status.busy": "2025-05-25T05:31:58.853840Z",
     "iopub.status.idle": "2025-05-25T05:31:59.077531Z",
     "shell.execute_reply": "2025-05-25T05:31:59.076556Z"
    },
    "papermill": {
     "duration": 0.230002,
     "end_time": "2025-05-25T05:31:59.079209",
     "exception": false,
     "start_time": "2025-05-25T05:31:58.849207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 05:31:58.869063: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "model = Sequential([\n",
    "    Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a796ad9",
   "metadata": {
    "papermill": {
     "duration": 0.00353,
     "end_time": "2025-05-25T05:31:59.086689",
     "exception": false,
     "start_time": "2025-05-25T05:31:59.083159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Our Soil Classification Model\n",
    "\n",
    "**Model Structure:**\n",
    "\n",
    "- Input Layer: Takes soil images (224x224 pixels with 3 color channels)\n",
    "- Convolution Blocks (Feature Extractors):\n",
    "  - Each block has:\n",
    "    - Conv2D layer (detects patterns like edges/textures)\n",
    "    - MaxPooling (reduces image size while keeping important features)\n",
    "  - Progressively increases filters (32 → 64 → 128) to catch complex patterns\n",
    "\n",
    "**Classifier Part:**\n",
    "  - Flatten layer (converts 2D features to 1D)\n",
    "  - Dense layer (128 neurons) for decision making\n",
    "  - Dropout (0.5) to prevent overfitting (randomly ignores half the neurons)\n",
    "  - Final output layer (softmax) gives probability for each soil type\n",
    "\n",
    "\n",
    "**Why This Works:**\n",
    "\n",
    "- Simple but effective CNN architecture\n",
    "- Gets progressively smarter about soil features\n",
    "- Balanced to avoid memorizing (dropout helps)\n",
    "- Standard settings that usually work well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2041fa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T05:31:59.095993Z",
     "iopub.status.busy": "2025-05-25T05:31:59.095116Z",
     "iopub.status.idle": "2025-05-25T05:52:40.150693Z",
     "shell.execute_reply": "2025-05-25T05:52:40.149824Z"
    },
    "papermill": {
     "duration": 1241.061962,
     "end_time": "2025-05-25T05:52:40.152338",
     "exception": false,
     "start_time": "2025-05-25T05:31:59.090376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 3s/step - accuracy: 0.4099 - loss: 1.8687 - val_accuracy: 0.8512 - val_loss: 0.5173\n",
      "Epoch 2/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.7396 - loss: 0.7478 - val_accuracy: 0.6570 - val_loss: 1.1983\n",
      "Epoch 3/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.7430 - loss: 0.6256 - val_accuracy: 0.8347 - val_loss: 0.3868\n",
      "Epoch 4/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.8093 - loss: 0.4489 - val_accuracy: 0.8884 - val_loss: 0.3095\n",
      "Epoch 5/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.8173 - loss: 0.4111 - val_accuracy: 0.7934 - val_loss: 0.3694\n",
      "Epoch 6/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.8326 - loss: 0.4269 - val_accuracy: 0.7397 - val_loss: 0.4133\n",
      "Epoch 7/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.8674 - loss: 0.3425 - val_accuracy: 0.8306 - val_loss: 0.2995\n",
      "Epoch 8/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.8630 - loss: 0.2921 - val_accuracy: 0.7851 - val_loss: 0.3694\n",
      "Epoch 9/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.8686 - loss: 0.3198 - val_accuracy: 0.7934 - val_loss: 0.3311\n",
      "Epoch 10/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.8902 - loss: 0.3011 - val_accuracy: 0.7438 - val_loss: 0.4162\n",
      "Epoch 11/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.9024 - loss: 0.2620 - val_accuracy: 0.9298 - val_loss: 0.1868\n",
      "Epoch 12/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 2s/step - accuracy: 0.9139 - loss: 0.2520 - val_accuracy: 0.9091 - val_loss: 0.1793\n",
      "Epoch 13/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.8976 - loss: 0.2625 - val_accuracy: 0.8306 - val_loss: 0.4317\n",
      "Epoch 14/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.8806 - loss: 0.2946 - val_accuracy: 0.8512 - val_loss: 0.2884\n",
      "Epoch 15/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.9071 - loss: 0.2614 - val_accuracy: 0.9091 - val_loss: 0.1953\n",
      "Epoch 16/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.8878 - loss: 0.2836 - val_accuracy: 0.7025 - val_loss: 0.8255\n",
      "Epoch 17/30\n",
      "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.8645 - loss: 0.2995 - val_accuracy: 0.8884 - val_loss: 0.2441\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a44ed6",
   "metadata": {
    "papermill": {
     "duration": 0.03451,
     "end_time": "2025-05-25T05:52:40.222972",
     "exception": false,
     "start_time": "2025-05-25T05:52:40.188462",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Training Our Model\n",
    "\n",
    " Smart Training Helpers (Callbacks):\n",
    "- **Early Stopping**:\n",
    "  - Stops training if model doesn't improve for 5 straight rounds\n",
    "  - Keeps the best version of the model\n",
    "- **Model Checkpoint**:\n",
    "  - Saves the best model automatically as 'best_model.h5'\n",
    "  - Only keeps the best version (saves disk space)\n",
    "\n",
    "Training Process:\n",
    "- Runs for maximum 30 rounds (epochs)\n",
    "- Uses:\n",
    "  - Training data (to learn patterns)\n",
    "  - Validation data (to check progress)\n",
    "- Automatically stops if not improving \n",
    "\n",
    "Why This Matters:\n",
    "- Prevents wasting time on useless training\n",
    "- Ensures we keep the best model version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7639e06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T05:52:40.294197Z",
     "iopub.status.busy": "2025-05-25T05:52:40.293849Z",
     "iopub.status.idle": "2025-05-25T05:52:47.711011Z",
     "shell.execute_reply": "2025-05-25T05:52:47.709972Z"
    },
    "papermill": {
     "duration": 7.454971,
     "end_time": "2025-05-25T05:52:47.712705",
     "exception": false,
     "start_time": "2025-05-25T05:52:40.257734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 588ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions \n",
    "test_preds = model.predict(test_generator)\n",
    "predicted_classes = np.argmax(test_preds, axis=1)\n",
    "class_labels = list(train_generator.class_indices.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b4d6dc",
   "metadata": {
    "papermill": {
     "duration": 0.035389,
     "end_time": "2025-05-25T05:52:47.794457",
     "exception": false,
     "start_time": "2025-05-25T05:52:47.759068",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*This code generates soil type predictions on test images, converting the model's probability outputs into specific class predictions. It identifies the most likely soil class for each image and maps these predictions to the actual class names used during training. The final output tells us which soil type the model believes each test image contains.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bb0d687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-25T05:52:47.866746Z",
     "iopub.status.busy": "2025-05-25T05:52:47.866066Z",
     "iopub.status.idle": "2025-05-25T05:52:47.887143Z",
     "shell.execute_reply": "2025-05-25T05:52:47.886275Z"
    },
    "papermill": {
     "duration": 0.058687,
     "end_time": "2025-05-25T05:52:47.888502",
     "exception": false,
     "start_time": "2025-05-25T05:52:47.829815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction distribution:\n",
      "soil_type\n",
      "Black Soil       35.1%\n",
      "Red soil         29.8%\n",
      "Clay soil        18.0%\n",
      "Alluvial soil    17.1%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "First 5 predictions:\n",
      "           image_id      soil_type\n",
      "0  img_0f035b97.jpg  Alluvial soil\n",
      "1  img_f13af256.jpg     Black Soil\n",
      "2  img_15b41dbc.jpg     Black Soil\n",
      "3  img_cfb4fc7a.jpg     Black Soil\n",
      "4  img_683111fb.jpg     Black Soil\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creating submission DataFrame \n",
    "submission = pd.DataFrame({\n",
    "    'image_id': test_df['image_id'],\n",
    "    'soil_type': [class_labels[i] for i in predicted_classes]\n",
    "})\n",
    "\n",
    "# Add summary statistics\n",
    "print(\"\\nPrediction distribution:\")\n",
    "print(submission['soil_type'].value_counts(normalize=True).apply(lambda x: f\"{x:.1%}\"))\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nFirst 5 predictions:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c0bc4",
   "metadata": {
    "papermill": {
     "duration": 0.035508,
     "end_time": "2025-05-25T05:52:47.959456",
     "exception": false,
     "start_time": "2025-05-25T05:52:47.923948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " *This code organizes our model's predictions into a submission file. It creates a table matching each test image with its predicted soil type, shows what percentage of each soil type was predicted, then saves everything to a CSV file while displaying a sample of the first 5 predictions.*"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12375409,
     "sourceId": 102672,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1281.809809,
   "end_time": "2025-05-25T05:52:51.299842",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-25T05:31:29.490033",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
