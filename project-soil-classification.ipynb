{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102672,"databundleVersionId":12375409,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing required libraries for this project:-\nimport os\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, f1_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:03:14.073650Z","iopub.execute_input":"2025-05-23T15:03:14.073955Z","iopub.status.idle":"2025-05-23T15:03:14.079669Z","shell.execute_reply.started":"2025-05-23T15:03:14.073930Z","shell.execute_reply":"2025-05-23T15:03:14.078414Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# **Tools & Libraries Used**\n1. Python (main programming language)\n\n2. TensorFlow/Keras (for building the neural network)\n\n3. NumPy & Pandas (for data handling)\n\n4. scikit-learn (for splitting data and evaluation)\n\n5. OpenCV (for image processing)","metadata":{}},{"cell_type":"code","source":"\n# Constants\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32\nEPOCHS = 30\n\n# Data paths (adjust to your actual paths)\nTRAIN_DIR = '/kaggle/input/soil-classification/soil_classification-2025/train'\nTEST_DIR = '/kaggle/input/soil-classification/soil_classification-2025/test'\nTRAIN_CSV = '/kaggle/input/soil-classification/soil_classification-2025/train_labels.csv'\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:03:21.806631Z","iopub.execute_input":"2025-05-23T15:03:21.806973Z","iopub.status.idle":"2025-05-23T15:03:21.811815Z","shell.execute_reply.started":"2025-05-23T15:03:21.806951Z","shell.execute_reply":"2025-05-23T15:03:21.810837Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"#  Configuration Settings\n\nImage Settings:\n  - `IMG_SIZE = (224, 224)` → All soil images will be resized to 224x224 pixels\n  - `BATCH_SIZE = 32` → Processes 32 images at once during training\n\nTraining Control:\n  - `EPOCHS = 30` → The model will go through the entire dataset 30 times\n\nFile Paths:\n  - `TRAIN_DIR` → Location of training images\n  - `TEST_DIR` → Location of test images\n  - `TRAIN_CSV` → File containing image labels (what soil type each image shows)\n\n","metadata":{}},{"cell_type":"code","source":"# Load and prepare data\ntrain_df = pd.read_csv(TRAIN_CSV)\ntest_files = [f for f in os.listdir(TEST_DIR) if f.endswith(('.jpg', '.jpeg', '.png'))]\ntest_df = pd.DataFrame({'image_id': test_files})\n\n# Verifying classes \nprint(\"Training data class distribution:\")\nprint(train_df['soil_type'].value_counts(normalize=True).apply(lambda x: f\"{x:.1%}\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:03:36.630107Z","iopub.execute_input":"2025-05-23T15:03:36.630550Z","iopub.status.idle":"2025-05-23T15:03:36.650399Z","shell.execute_reply.started":"2025-05-23T15:03:36.630521Z","shell.execute_reply":"2025-05-23T15:03:36.649211Z"}},"outputs":[{"name":"stdout","text":"Training data class distribution:\nsoil_type\nAlluvial soil    43.2%\nRed soil         21.6%\nBlack Soil       18.9%\nClay soil        16.3%\nName: proportion, dtype: object\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"**loads soil image data from files & checks distribution of different soil types in training set:**\n\n\n1. Reads the training labels from CSV\n2. Finds all test images in the test folder\n3. Shows what percentage of each soil type we have in our training data\n","metadata":{}},{"cell_type":"code","source":"# Data generators\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n\n# Create generators\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=TRAIN_DIR,\n    x_col='image_id',\n    y_col='soil_type',\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True\n)\n\nval_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=TRAIN_DIR,\n    x_col='image_id',\n    y_col='soil_type',\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False\n)\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory=TEST_DIR,\n    x_col='image_id',\n    y_col=None,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=None,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:03:42.912067Z","iopub.execute_input":"2025-05-23T15:03:42.912431Z","iopub.status.idle":"2025-05-23T15:03:45.565027Z","shell.execute_reply.started":"2025-05-23T15:03:42.912405Z","shell.execute_reply":"2025-05-23T15:03:45.564086Z"}},"outputs":[{"name":"stdout","text":"Found 972 validated image filenames belonging to 4 classes.\nFound 242 validated image filenames belonging to 4 classes.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 8 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 8 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 339 validated image filenames.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"#  Data Preparation\n\n- **Image Processing**:\n  - Normalizes pixel values (0-1) by dividing by 255\n  - Adds variations to training images:\n    - Random rotations (up to 20 degrees)\n    - Small left/right and up/down shifts\n    - Horizontal flipping\n  - Keeps test images unchanged (only normalizes them)\n\n- **Data Generators**:\n  - `train_generator`: \n    - Takes images from training folder\n    - Uses 80% of data for actual training\n    - Shuffles images for better learning\n  - `val_generator`: \n    - Uses remaining 20% for validation\n    - Doesn't shuffle (for proper evaluation)\n  - `test_generator`:\n    - Only for final testing\n    - No labels needed (for predictions)","metadata":{}},{"cell_type":"code","source":"# Model architecture\nmodel = Sequential([\n    Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n    Conv2D(32, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(len(train_generator.class_indices), activation='softmax')\n])\n\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:04:00.938864Z","iopub.execute_input":"2025-05-23T15:04:00.939604Z","iopub.status.idle":"2025-05-23T15:04:01.070063Z","shell.execute_reply.started":"2025-05-23T15:04:00.939563Z","shell.execute_reply":"2025-05-23T15:04:01.069173Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Our Soil Classification Model\n\n**Model Structure:**\n\n- Input Layer: Takes soil images (224x224 pixels with 3 color channels)\n- Convolution Blocks (Feature Extractors):\n  - Each block has:\n    - Conv2D layer (detects patterns like edges/textures)\n    - MaxPooling (reduces image size while keeping important features)\n  - Progressively increases filters (32 → 64 → 128) to catch complex patterns\n\n**Classifier Part:**\n  - Flatten layer (converts 2D features to 1D)\n  - Dense layer (128 neurons) for decision making\n  - Dropout (0.5) to prevent overfitting (randomly ignores half the neurons)\n  - Final output layer (softmax) gives probability for each soil type\n\n\n**Why This Works:**\n\n- Simple but effective CNN architecture\n- Gets progressively smarter about soil features\n- Balanced to avoid memorizing (dropout helps)\n- Standard settings that usually work well","metadata":{}},{"cell_type":"code","source":"# Callbacks\ncallbacks = [\n    EarlyStopping(patience=5, restore_best_weights=True),\n    ModelCheckpoint('best_model.h5', save_best_only=True)\n]\n\n# Train model\nhistory = model.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=val_generator,\n    callbacks=callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:23:49.773924Z","iopub.execute_input":"2025-05-23T15:23:49.774274Z","iopub.status.idle":"2025-05-23T15:30:44.979297Z","shell.execute_reply.started":"2025-05-23T15:23:49.774226Z","shell.execute_reply":"2025-05-23T15:30:44.978449Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/30\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 2s/step - accuracy: 0.8405 - loss: 0.3759 - val_accuracy: 0.8471 - val_loss: 0.3065\nEpoch 2/30\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.8367 - loss: 0.4009 - val_accuracy: 0.6777 - val_loss: 0.8216\nEpoch 3/30\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 2s/step - accuracy: 0.8701 - loss: 0.3792 - val_accuracy: 0.8347 - val_loss: 0.3688\nEpoch 4/30\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2s/step - accuracy: 0.8714 - loss: 0.3229 - val_accuracy: 0.7975 - val_loss: 0.5321\nEpoch 5/30\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.9009 - loss: 0.2707 - val_accuracy: 0.8347 - val_loss: 0.3486\nEpoch 6/30\n\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 2s/step - accuracy: 0.8848 - loss: 0.2799 - val_accuracy: 0.8306 - val_loss: 0.4692\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"#  Training Our Model\n\n Smart Training Helpers (Callbacks):\n- **Early Stopping**:\n  - Stops training if model doesn't improve for 5 straight rounds\n  - Keeps the best version of the model\n- **Model Checkpoint**:\n  - Saves the best model automatically as 'best_model.h5'\n  - Only keeps the best version (saves disk space)\n\nTraining Process:\n- Runs for maximum 30 rounds (epochs)\n- Uses:\n  - Training data (to learn patterns)\n  - Validation data (to check progress)\n- Automatically stops if not improving \n\nWhy This Matters:\n- Prevents wasting time on useless training\n- Ensures we keep the best model version\n","metadata":{}},{"cell_type":"code","source":"# Generate predictions \ntest_preds = model.predict(test_generator)\npredicted_classes = np.argmax(test_preds, axis=1)\nclass_labels = list(train_generator.class_indices.keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:30:57.163325Z","iopub.execute_input":"2025-05-23T15:30:57.163660Z","iopub.status.idle":"2025-05-23T15:31:03.633174Z","shell.execute_reply.started":"2025-05-23T15:30:57.163639Z","shell.execute_reply":"2025-05-23T15:31:03.632102Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 520ms/step\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"*This code generates soil type predictions on test images, converting the model's probability outputs into specific class predictions. It identifies the most likely soil class for each image and maps these predictions to the actual class names used during training. The final output tells us which soil type the model believes each test image contains.*","metadata":{}},{"cell_type":"code","source":"\n# creating submission DataFrame \nsubmission = pd.DataFrame({\n    'image_id': test_df['image_id'],\n    'soil_type': [class_labels[i] for i in predicted_classes]\n})\n\n# Add summary statistics\nprint(\"\\nPrediction distribution:\")\nprint(submission['soil_type'].value_counts(normalize=True).apply(lambda x: f\"{x:.1%}\"))\n\n# Save to CSV\nsubmission.to_csv('submission.csv', index=False)\nprint(\"\\nFirst 5 predictions:\")\nprint(submission.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T15:31:18.966488Z","iopub.execute_input":"2025-05-23T15:31:18.966807Z","iopub.status.idle":"2025-05-23T15:31:18.978693Z","shell.execute_reply.started":"2025-05-23T15:31:18.966784Z","shell.execute_reply":"2025-05-23T15:31:18.977742Z"}},"outputs":[{"name":"stdout","text":"\nPrediction distribution:\nsoil_type\nBlack Soil       31.0%\nRed soil         28.9%\nClay soil        26.8%\nAlluvial soil    13.3%\nName: proportion, dtype: object\n\nFirst 5 predictions:\n           image_id      soil_type\n0  img_0f035b97.jpg  Alluvial soil\n1  img_f13af256.jpg      Clay soil\n2  img_15b41dbc.jpg  Alluvial soil\n3  img_cfb4fc7a.jpg     Black Soil\n4  img_683111fb.jpg     Black Soil\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":" *This code organizes our model's predictions into a submission file. It creates a table matching each test image with its predicted soil type, shows what percentage of each soil type was predicted, then saves everything to a CSV file while displaying a sample of the first 5 predictions.*","metadata":{}}]}